{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from heavylight import LightModel\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "spots = torch.FloatTensor(\n",
    "    [\n",
    "        -0.00217,\n",
    "        -0.00163,\n",
    "        -0.00119,\n",
    "        -0.00025,\n",
    "        0.0006,\n",
    "        0.00177,\n",
    "        0.00302,\n",
    "        0.00437,\n",
    "        0.00558,\n",
    "        0.00676,\n",
    "        0.0077,\n",
    "        0.00849,\n",
    "        0.00925,\n",
    "        0.00991,\n",
    "        0.01048,\n",
    "        0.01087,\n",
    "        0.01121,\n",
    "        0.01152,\n",
    "        0.01179,\n",
    "        0.01204,\n",
    "    ]\n",
    ")\n",
    "zcbs = (1 + spots) ** (-torch.arange(1, spots.size(0) + 1))\n",
    "# r0 = 0.04 but as a torch tensor\n",
    "r0 = torch.tensor(0.04)\n",
    "a = torch.tensor(0.2)\n",
    "b = torch.tensor(0.041)\n",
    "sigma = torch.tensor(0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIRModel(LightModel):\n",
    "    \"\"\"\n",
    "    Currently uses Euler discretization to simulate the CIR model.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, a, b, sigma, r_init, init_time: int, num_sims: int, dt: float):\n",
    "        super(CIRModel, self).__init__()\n",
    "        self.a = a\n",
    "        self.b = b\n",
    "        self.sigma = sigma\n",
    "        self.r_init = r_init\n",
    "        self.init_time = init_time\n",
    "        self.num_sims = num_sims\n",
    "        self.dt = torch.tensor(dt)\n",
    "\n",
    "    def r(self, t: int):\n",
    "        assert t >= self.init_time\n",
    "        if t == self.init_time:\n",
    "            return self.r_init.expand(self.num_sims)\n",
    "        r_prev_non_neg = torch.clamp(self.r(t-1), min=0)\n",
    "        return self.r(t-1) + self.a * (self.b - r_prev_non_neg) * self.dt + self.sigma * torch.sqrt(r_prev_non_neg) * torch.randn_like(self.r_init) * torch.sqrt(self.dt)\n",
    "    \n",
    "    def discount(self, t: int):\n",
    "        assert t >= self.init_time\n",
    "        if t == self.init_time:\n",
    "            return torch.ones(self.num_sims)\n",
    "        return self.discount(t-1) * torch.exp(-self.dt * 0.5 * (self.r(t-1) + self.r(t)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: integrate with the CIR, this is from someone else's code but not currently working with my CIR to make a CIR++ model\n",
    "\n",
    "class ShiftedModel:\n",
    "    def __init__(self, basemodel: CIR, zcbs: torch.Tensor):\n",
    "        self.zcbs = zcbs\n",
    "        self.basemodel = basemodel\n",
    "        self.xzcbsbase = self.basemodel.init_zcb_price(\n",
    "            torch.arange(0, zcbs.size(0) + 1)\n",
    "        )\n",
    "        self.zcbsbase = self.xzcbsbase[1:]\n",
    "        self.xzcbs = torch.cat((self.zcbs.data.new(1).fill_(1.0), self.zcbs), dim=0)\n",
    "\n",
    "    def simulate(self, num_sims, num_years, steps_per_year=12):\n",
    "        r, d_base = self.basemodel.simulate(\n",
    "            num_sims, num_years, steps_per_year=steps_per_year\n",
    "        )\n",
    "        numYears_plus_one = r.size(0)\n",
    "        d = d_base * (\n",
    "            self.xzcbs[:numYears_plus_one].unsqueeze(1)\n",
    "            / self.xzcbsbase[:numYears_plus_one].unsqueeze(1)\n",
    "        )\n",
    "        return r, d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.4818,  0.5948, -0.6709, -2.4159,  0.8579,  0.2487,  1.2829, -0.5595,\n",
      "          0.1507,  0.4305],\n",
      "        [ 0.5153,  0.2828, -0.2487, -0.6782,  0.6893,  0.0753,  0.8473,  0.0270,\n",
      "         -1.0455, -1.2770],\n",
      "        [-0.8772, -1.0671,  1.1152, -0.1365,  1.8599,  0.2909, -1.1435,  0.3790,\n",
      "          0.8732, -0.8800]])\n"
     ]
    }
   ],
   "source": [
    "class MultivariateSampler(LightModel):\n",
    "    def __init__(self, covariance_matrix: torch.Tensor, num_samples: int):\n",
    "        self.m = MultivariateNormal(\n",
    "            torch.zeros(covariance_matrix.size(0)),\n",
    "            covariance_matrix\n",
    "        )\n",
    "        self.num_samples = num_samples\n",
    "\n",
    "    def sample(self, t: int):\n",
    "        return self.m.sample(torch.Size([self.num_samples])).T\n",
    "    \n",
    "    def dWtx(self, t: int):\n",
    "        return self.sample(t)[0]\n",
    "    def dWtS(self, t: int):\n",
    "        return self.sample(t)[1]\n",
    "    def dWtR(self, t: int):\n",
    "        return self.sample(t)[2]\n",
    "\n",
    "from torch.distributions import MultivariateNormal\n",
    "\n",
    "covariance_matrix = torch.tensor([[1.0, 0.1, 0.0], [0.1, 1.0, 0.0], [0.0, 0.0, 1.0]])\n",
    "m = MultivariateNormal(torch.tensor([0.0, 0.0, 0.0]), covariance_matrix)\n",
    "\n",
    "# m.sample()  # normally distributed with mean=`[0,0,0]` and covariance_matrix=`I`\n",
    "# how to sample to have 1000 observationns of each type\n",
    "ms = MultivariateSampler(covariance_matrix, 10)\n",
    "print(ms.sample(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: This is not done\n",
    "class HestonModel(LightModel):\n",
    "\n",
    "    def __init__(self, kappa, theta, epsilon, r_init, v_init, init_time: int, num_sims: int, dt: float):\n",
    "        super(HestonModel, self).__init__()\n",
    "        self.kappa = kappa\n",
    "        self.theta = theta\n",
    "        self.epsilon = epsilon\n",
    "        self.r_init = r_init\n",
    "        self.v_init = v_init\n",
    "        self.init_time = init_time\n",
    "        self.num_sims = num_sims\n",
    "        self.dt = torch.tensor(dt)\n",
    "\n",
    "    def r(self, t: int):\n",
    "        assert t >= self.init_time\n",
    "        if t == self.init_time:\n",
    "            return self.r_init.expand(self.num_sims)\n",
    "        r_prev_non_neg = torch.clamp(self.r(t-1), min=0)\n",
    "        return self.r(t-1) + self.a * (self.b - r_prev_non_neg) * self.dt + self.sigma * torch.sqrt(r_prev_non_neg) * torch.randn_like(self.r(t-1)) * torch.sqrt(self.dt)\n",
    "    \n",
    "    def discount(self, t: int):\n",
    "        assert t >= self.init_time\n",
    "        if t == self.init_time:\n",
    "            return torch.ones(self.num_sims)\n",
    "        return self.discount(t-1) * torch.exp(-self.dt * 0.5 * (self.r(t-1) + self.r(t)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9671)\n",
      "tensor(0.9671)\n"
     ]
    }
   ],
   "source": [
    "cir_model = CIRModel(a, b, sigma, r0, 0, 1000, 1 / 12)\n",
    "print(cir_model.discount(10).mean())\n",
    "# cir_model.ResetCache()\n",
    "print(cir_model.discount(10).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step through it\n",
    "\n",
    "We are going to take the basemodel and\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
